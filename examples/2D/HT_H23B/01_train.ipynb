{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 1:** Training a <nobr>Micro$\\mathbb{S}$plit</nobr> Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction - what does this notebook do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Despite network training arguably being the most important step, the execution of this notebook is optional. If you do not run this notebook, in Step 2 (prediction) we offer you to use pretrained model checkpoints. Like in any respected cooking show: \"we have already prepared someting before the show\"... üòâ\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will train a <nobr>Micro$\\mathbb{S}$plit</nobr> network for removing unwanted imaging artifacts from our HT_H23B dataset. \n",
    "\n",
    "More specifically, we imaged the post-mitotic neuronal marker CTIP2 in sliced hPSC-derived forebrain\n",
    "organoids using a secondary antibody conjugated to a 555 dye. The resulting image data not only had\n",
    "CTIP2+ nuclear staining (wanted signal), but also puncta that accumulated because of non-specific signal\n",
    "(i.e. undesired artifacts).\n",
    "Ideally, we could use MicroSplit to unmix the labeled nuclei (desired image content) and the undesired\n",
    "puncta (i.e. imaging artifacts). However, for this we would need training targets that contain only nuclei\n",
    "and others that contain only puncta, a requirement that this experimental setup does not\n",
    "permit. That's why we manually selected image regions that show\n",
    "only the artifacts (puncta) or only the desired structures (the signal, in this example, nuclei). The selected\n",
    "image regions are then combined and used to train a MicroSplit\n",
    "network. Since crops without puncta or crops that show only puncta are of limited size with respect to full\n",
    "microscopy images (the smallest crops we collected were 100 ‚Üí 100 pixels), lateral contextualization could not be used and was therefore disabled during training. In total, we have manually\n",
    "cropped 82 content regions and 48 puncta regions from the data. This took an analyst about eight hours of focused work.\n",
    "\n",
    "Here, we assume that images of each single structure exist, but we no longer assume that all structures have\n",
    "been imaged in each sample. As before, here we also generate superimposed inputs by summing images showing different fluorescent structures. However, unlike before, summed-up input images no longer originate\n",
    "from the same sample, and any spatial correlations that might exist between these cellular structures\n",
    "are lost\n",
    "\n",
    "This dataset contains 2 labeled structures:\n",
    "1. Puncta\n",
    "2. Foreground\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: what is <nobr>Micro$\\mathbb{S}$plit</nobr> training all about?\n",
    "Training is done in a supervised way. For every input patch, we have the two corresponding target patches using which we train our MicroSplit. \n",
    "Besides the primary input patch, we also feed LC inputs to MicroSplit. We introduced LC inputs in [ŒºSplit: efficient image decomposition for microscopy data](https://openaccess.thecvf.com/content/ICCV2023/papers/Ashesh_uSplit_Image_Decomposition_for_Fluorescence_Microscopy_ICCV_2023_paper.pdf), which enabled the network to understand the global spatial context around the input patch.\n",
    "\n",
    "To enable unsupervised denoising, we integrated the KL loss formulation and Noise models from our previous work [denoiSplit: a method for joint microscopy image splitting and unsupervised denoising](https://eccv.ecva.net/virtual/2024/poster/2538). \n",
    "\n",
    "The loss function for MicroSplit is a weighted average of denoiSplit loss and ŒºSplit loss. For both denoiSplit and ŒºSplit, their loss expression have two terms: KL divergence loss and likelihood loss. For more details, please refer to the respective papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do it, let's train a <nobr>Micro$\\mathbb{S}$plit</nobr> Model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You are new to Jupyter notebooks?** Don't worry, if you take the time to read all our explanations, we will guide you through them and you will understand a lot. Still, you will likely end up less frustrated, if you do not even start with the ambition to interpret the purpose of every line of code.\n",
    "Let's start with a nice example, the imports to enable the remainder of this notebook. Ignore it (unless you know what you are doing) and just click **‚áß*Shift* + ‚èé*Enter*** to execute this (and all other) code cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the things we need further down\n",
    "\n",
    "import pooch\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from careamics.lightning import VAEModule\n",
    "\n",
    "from microsplit_reproducibility.configs.factory import (\n",
    "    create_algorithm_config,\n",
    "    get_likelihood_config,\n",
    "    get_loss_config,\n",
    "    get_model_config,\n",
    "    get_optimizer_config,\n",
    "    get_training_config,\n",
    "    get_lr_scheduler_config,\n",
    ")\n",
    "from microsplit_reproducibility.utils.callbacks import get_callbacks\n",
    "from microsplit_reproducibility.utils.io import load_checkpoint, load_checkpoint_path\n",
    "from microsplit_reproducibility.datasets import create_train_val_datasets\n",
    "from microsplit_reproducibility.utils.utils import (\n",
    "    plot_training_metrics,\n",
    "    plot_training_outputs,\n",
    ")\n",
    "\n",
    "# Dataset specific imports...\n",
    "from microsplit_reproducibility.configs.parameters.HT_H23B import get_microsplit_parameters\n",
    "from microsplit_reproducibility.configs.data.HT_H23B import get_data_configs\n",
    "from microsplit_reproducibility.datasets.HT_H23B import get_train_val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 1.1:** Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data\n",
    "Depending on your internet connection, this will take a while...\n",
    "\n",
    "Note that appropriate noise models will only be downloaded if they were not created by executing the notebook `00_noisemodels.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = pooch.create(\n",
    "    path=f\"./data/\",\n",
    "    base_url=f\"https://download.fht.org/jug/msplit/ht_h23b/data/\",\n",
    "    registry={f\"ht_h23b.zip\": None},\n",
    ")\n",
    "\n",
    "NOISE_MODELS = pooch.create(\n",
    "    path=f\"./noise_models/\",\n",
    "    base_url=f\"https://download.fht.org/jug/msplit/ht_h23b/noise_models/\",\n",
    "    registry={\n",
    "        f\"ht_h23b_nm_raw_data.npz\": None,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the following notebook will download all you need. In case you see no messages announcing any downloads, you already have this data in the notebook folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in NOISE_MODELS.registry:\n",
    "    NOISE_MODELS.fetch(fname, progressbar=True)\n",
    "print('---------')\n",
    "for fname in DATA.registry:\n",
    "    DATA.fetch(fname, processor=pooch.Unzip(), progressbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we load the image data to be processed\n",
    "\n",
    "Note that depending on the amount of GPU memory you have available, you might want to adjust the batch size. The default is 64, but you can reduce it to 32 if you run out of memory by changing the <i> batch_size </i> parameter in <i> get_microsplit_parameters </i> below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** if you want to use the noise model you trained in the previous notebook, change the `nm_fname` in the cell below to `user_trained_noise_model.npz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm_fname = \"ht_h23b_nm_raw_data.npz\"\n",
    "# setting up train, validation, and test data configs\n",
    "train_data_config, val_data_config, test_data_config = get_data_configs()\n",
    "# setting up MicroSplit parametrization\n",
    "experiment_params = get_microsplit_parameters(nm_path=NOISE_MODELS.path /nm_fname, batch_size=64\n",
    ")\n",
    "\n",
    "# start the download of required files\n",
    "train_dset, val_dset, _, data_stats = create_train_val_datasets(\n",
    "    datapath=DATA.path / f\"ht_h23b.zip.unzip/ht_h23b\",\n",
    "    train_config=train_data_config,\n",
    "    val_config=val_data_config,\n",
    "    test_config=val_data_config,\n",
    "    load_data_func=get_train_val_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Optional:*** inspect data configurations and <nobr>Micro$\\mathbb{S}$plit</nobr> config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_show_configs = True\n",
    "\n",
    "if do_show_configs:\n",
    "    print('FYI: train_data_config')\n",
    "    print('----------------------')\n",
    "    for cfg in train_data_config:\n",
    "        print(cfg)\n",
    "\n",
    "    print('\\nFYI: experiment_params')\n",
    "    print('----------------------')\n",
    "    print(experiment_params)\n",
    "else:\n",
    "    print('You opted out of having all params printed... swiftly moving on... ;)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final step: create Dataloaders for network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dloader = DataLoader(\n",
    "    train_dset,\n",
    "    batch_size=experiment_params[\"batch_size\"],\n",
    "    num_workers=experiment_params[\"num_workers\"],\n",
    "    shuffle=True,\n",
    ")\n",
    "val_dloader = DataLoader(\n",
    "    val_dset,\n",
    "    batch_size=experiment_params[\"batch_size\"],\n",
    "    num_workers=experiment_params[\"num_workers\"],\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 1.2:** Prepare <nobr>Micro$\\mathbb{S}$plit</nobr> Training\n",
    "Next, we create all the configs for the upcoming network training run. These lines are not very intuitive and if you don't intend to dive really deep into CAREamics and the internals of <nobr>Micro$\\mathbb{S}$plit</nobr>, you might just execute these cells and move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making our data_stas known to the experiment we prepare\n",
    "experiment_params[\"data_stats\"] = data_stats\n",
    "\n",
    "# setting up training losses and model config (using default parameters)\n",
    "loss_config = get_loss_config(**experiment_params)\n",
    "model_config = get_model_config(**experiment_params)\n",
    "gaussian_lik_config, noise_model_config, nm_lik_config = get_likelihood_config(\n",
    "    **experiment_params\n",
    ")\n",
    "training_config = get_training_config(**experiment_params)\n",
    "\n",
    "# setting up learning rate scheduler and optimizer (using default parameters)\n",
    "lr_scheduler_config = get_lr_scheduler_config(**experiment_params)\n",
    "optimizer_config = get_optimizer_config(**experiment_params)\n",
    "\n",
    "# finally, assemble the full set of experiment configurations...\n",
    "experiment_config = create_algorithm_config(\n",
    "    algorithm=experiment_params[\"algorithm\"],\n",
    "    loss_config=loss_config,\n",
    "    model_config=model_config,\n",
    "    gaussian_lik_config=gaussian_lik_config,\n",
    "    nm_config=noise_model_config,\n",
    "    nm_lik_config=nm_lik_config,\n",
    "    lr_scheduler_config=lr_scheduler_config,\n",
    "    optimizer_config=optimizer_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wanna trade speed for model quality?\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> If you simply want to go over this notebook quickly and you don't care about training a competitive model, set <i>`reduce_training_epochs=True`</i> in the cell below. \n",
    "\n",
    "Note that if <i> reduce_training_epochs </i> is set to <i>False </i>, the default number of epochs is 400. However, early stopping will be invoked when the loss is no longer decreasing, so the actual number of epochs trained will most likely be less than 400.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_training_epochs = True\n",
    "\n",
    "# if True, train for only 10 epochs (quick'n'dirty testing mode)\n",
    "if reduce_training_epochs:\n",
    "    training_config.num_epochs = 10\n",
    "\n",
    "print(f'Will train for {training_config.num_epochs} epochs!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the <nobr>Micro$\\mathbb{S}$plit</nobr> model to be trained.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAEModule(algorithm_config=experiment_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show some training data for a final check!\n",
    "***Tip:*** we show you a few samples of the prepared training data. In case you don't like what you see, execute the cell again and other randomly chosen patches will be shown!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(15, 10), ncols=3)\n",
    "inp, tar = train_dset[0]\n",
    "ax[0].imshow(inp.squeeze())\n",
    "ax[0].set_title(\"Input\")\n",
    "ax[1].imshow(tar[0])\n",
    "ax[1].set_title(\"Target channel 1\")\n",
    "ax[2].imshow(tar[1])\n",
    "ax[2].set_title(\"Target channel 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 1.3:** Train the prepared model!\n",
    "***Note:*** if this takes too long, there were two places above where we gave you options to *(i)* reduce the amount of training data, and *(ii)* chose to train for fewer epochs. Revisit your choices if you want to!\n",
    "\n",
    "***Note:*** Depending on the amount of GPU memory you have available, you might want to adjust the batch size. The default is 32, but you can reduce it to 16 if you run out of memory by changing the <i> batch_size </i> parameter in <i> get_microsplit_parameters </i> above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a CAREamics 'Trainer'\n",
    "trainer = Trainer(\n",
    "    max_epochs=training_config.num_epochs,\n",
    "    # NOTE: if you are on a mac swap the accelerator to \"mps\"\n",
    "    # accelerator=‚Äúmps‚Äù,\n",
    "    accelerator=\"gpu\",\n",
    "    enable_progress_bar=True,\n",
    "    callbacks=get_callbacks(f\"./checkpoints/\"),\n",
    "    precision=training_config.precision,\n",
    "    gradient_clip_val=training_config.gradient_clip_val,\n",
    "    gradient_clip_algorithm=training_config.gradient_clip_algorithm,\n",
    ")\n",
    "# start the training - yay!\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=train_dloader,\n",
    "    val_dataloaders=val_dloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show training loss curves...\n",
    "Below, we plot for each epoch of your training run the *(i)* training reconstruction loss, *(ii)* training KL divergence loss, *(iii)* validation reconstruction loss, and *(iv)* validation PSNR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from microsplit_reproducibility.notebook_utils.HT_LIF24 import find_recent_metrics, plot_metrics\n",
    "df = read_csv(find_recent_metrics())\n",
    "plot_metrics(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You are done here! üëç Congratulations! üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
